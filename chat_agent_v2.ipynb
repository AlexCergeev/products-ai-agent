{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9054c69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "import html\n",
    "import random\n",
    "\n",
    "from rag import Rag\n",
    "from langchain_gigachat.chat_models import GigaChat\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from langchain.tools import tool\n",
    "from jira import JIRA \n",
    "from bs4 import BeautifulSoup as soup\n",
    "from _config import credentials, login, token_jira, TOKEN\n",
    "from urllib.parse import urlparse\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a9d49e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Инициализация модели GigaChat \n",
    "gigachat_model = GigaChat(\n",
    "    credentials=credentials,\n",
    "    verify_ssl_certs=False,\n",
    "    timeout=360,\n",
    "    temperature=0.18,\n",
    "    top_p=0.3,\n",
    "    model=\"GigaChat-2-Max\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa6f34bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "\n",
    "    def read(self, key):\n",
    "        return self.data.get(key, \"\")\n",
    "\n",
    "    def append(self, key, value):\n",
    "        if key in self.data:\n",
    "            self.data[key] += f\"\\n{value}\"\n",
    "        else:\n",
    "            self.data[key] = value\n",
    "\n",
    "    def clear(self):\n",
    "        self.data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7601b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_imp = Memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "849f0060",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = Rag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c186f797",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def data_loader(url_tz: str, url_code: str) -> str:\n",
    "    \"\"\"\n",
    "    Скачивает код по ссылке (url_code) и бизнес требование по ссылке (url_tz) с конфлюенса.\n",
    "    \n",
    "    Args:\n",
    "    url_tz: ссылка с требованиями на конфлюенсе str\n",
    "    url_code: ссылка на код на конфлюенсе str\n",
    "    return: Сообщение о статусе скачивания данных \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Начал скачивать данные!!!!!\")\n",
    "    # ТЗ\n",
    "    match = re.search(r'/pages/(\\d+)', url_tz)\n",
    "    match_tz =  match.group(1) if match else None\n",
    "    base_url = f\"https://accergeev.atlassian.net/wiki/rest/api/content/{match_tz}?expand=body.storage\"\n",
    "    auth = HTTPBasicAuth(login, token_jira)\n",
    "    if match_tz is not None:\n",
    "        response = requests.get(base_url, auth=auth)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            project_requirements = soup(data['body']['storage']['value'], 'html.parser').get_text(separator=\"\\n\", strip=True)\n",
    "            flag = False\n",
    "        else:\n",
    "            return f\"Ошибка:, {response.status_code, response.text}\"\n",
    "    else:\n",
    "        return 'В предоставленной ссылке для требований нет pageId.'\n",
    "        \n",
    "    # Проверяем ТЗ\n",
    "    messages = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\"\"Изучи следующий контекст шаг за шагом:\\n\n",
    "                1. Сначала внимательно прочитай предоставленный текст\\n\n",
    "                2. Проверь, является ли предоставленный текст бизнес требованием, а не кодом или просто случайным текстом. Бизнес требование имеет примерно такую структуру: формулирует, что должен делать разработчик, какие результаты ожидать и какие ограничения учитывать.\\n\n",
    "                3. Если предоставленный текст является бизнес требованием, то в итоговом ответе напиши - 'корректный формат требований', если нет, напиши - 'некорректный формат требований'\"\"\"\n",
    "    ), HumanMessage(content=project_requirements)]\n",
    "    time.sleep(1)\n",
    "    req_checker = gigachat_model.invoke(messages)\n",
    "    \n",
    "    \n",
    "    #Code\n",
    "    match = re.search(r'/pages/(\\d+)', url_code)\n",
    "    match_code =  match.group(1) if match else None\n",
    "    base_url = f\"https://accergeev.atlassian.net/wiki/rest/api/content/{match_code}?expand=body.storage\"\n",
    "    if match_code is not None:\n",
    "        response = requests.get(base_url, auth=auth)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            project_code = soup(data['body']['storage']['value'], 'html.parser').get_text(separator=\"\\n\", strip=True)\n",
    "            flag = False\n",
    "        else:\n",
    "            return f\"Ошибка:, {response.status_code, response.text}\"\n",
    "    else:\n",
    "        return 'В предоставленной ссылке для кода нет pageId.'\n",
    "        \n",
    "        \n",
    "    # Проверяем код    \n",
    "    messages_code = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\"\"Изучи следующий контекст шаг за шагом:\n",
    "                1. Сначала внимательно прочитай предоставленный текст\\n\n",
    "                2. Проверь, является ли предоставленный текст кодом на Python, Java, SQL, C++ или Go, а не бизнес требованием или просто случайным текстом.\\n\n",
    "                3. Если предоставленный текст является кодом, то в итоговом ответе напиши - 'корректный формат кода', если нет, напиши - 'некорректный формат кода'\"\"\"\n",
    "    ), HumanMessage(content=project_code)]\n",
    "    time.sleep(1)\n",
    "    code_checker = gigachat_model.invoke(messages_code) \n",
    "    \n",
    "    if ('некорректный' in code_checker.content.lower()) or ('некорректный' in req_checker.content.lower()):\n",
    "        asnwer = code_checker.content + '\\n' + req_checker.content\n",
    "        return asnwer\n",
    "    else:\n",
    "        memory_imp.append(\"Требования пользователя\", project_requirements)\n",
    "        memory_imp.append(\"Код пользователя\", project_code)\n",
    "        work_message = 'Данные загружены'\n",
    "        return work_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3da9fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def data_loader_init(tz: str, code: str) -> str:\n",
    "    \"\"\"\n",
    "    Сохраняет бизнес требование tz, которое передает пользователь, и код code\n",
    "    \n",
    "    tz: бизнес требование str\n",
    "    code: код str\n",
    "    return: Сообщение о получении данных \n",
    "    \"\"\"\n",
    "    # Проверяем ТЗ\n",
    "    messages = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\"\"Изучи следующий контекст шаг за шагом:\\n\n",
    "                1. Сначала внимательно прочитай предоставленный текст\\n\n",
    "                2. Проверь, является ли предоставленный текст бизнес требованием, а не кодом или просто случайным текстом. Бизнес требование имеет примерно такую структуру: формулирует, что должен делать разработчик, какие результаты ожидать и какие ограничения учитывать.\\n\n",
    "                3. Если предоставленный текст является бизнес требованием, то в итоговом ответе напиши - 'корректный формат требований', если нет, напиши - 'некорректный формат требований'\"\"\"\n",
    "    ), HumanMessage(content=tz)]\n",
    "    time.sleep(1)\n",
    "    req_checker = gigachat_model.invoke(messages)\n",
    "    \n",
    "    # Проверяем код    \n",
    "    messages_code = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\"\"Изучи следующий контекст шаг за шагом:\n",
    "                1. Сначала внимательно прочитай предоставленный текст\\n\n",
    "                2. Проверь, является ли предоставленный текст кодом на Python, Java, SQL, C++ или Go, а не бизнес требованием или просто случайным текстом.\\n\n",
    "                3. Если предоставленный текст является кодом, то в итоговом ответе напиши - 'корректный формат кода', если нет, напиши - 'некорректный формат кода'\"\"\"\n",
    "    ), HumanMessage(content=code)]\n",
    "    time.sleep(1)\n",
    "    code_checker = gigachat_model.invoke(messages_code) \n",
    "    \n",
    "    if ('некорректный' in code_checker.content.lower()) or ('некорректный' in req_checker.content.lower()):\n",
    "        asnwer = code_checker.content + '\\n' + req_checker.content\n",
    "        return asnwer\n",
    "    else:\n",
    "        memory_imp.append(\"Требования пользователя\", tz)\n",
    "        memory_imp.append(\"Код пользователя\", code)\n",
    "        work_message = 'Данные загружены'\n",
    "        return work_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad1e71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def req_analyzer(tz: str) -> str:\n",
    "    \"\"\"\n",
    "    Анализирует текстовые требования tz и возвращает их анализ.\n",
    "    \n",
    "    tz: бизнес требование str\n",
    "    return: Анализ требований str\n",
    "    \"\"\"\n",
    "    print(\"Начал анализ требований!!!!!\")\n",
    "    if 'Требования пользователя' in memory_imp.data:\n",
    "        message = memory_imp.read('Требования пользователя')\n",
    "    else:\n",
    "        message = tz\n",
    "    data_rag = rag.get_data(message)\n",
    "    rag_message = f'{message}\\n{data_rag}'\n",
    "    messages = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\"Задача: проанализировать текстовые требования на наличие логических ошибок, двусмысленных формулировок и противоречий.\\n\n",
    "        Выяви нечеткие определения, неопределённые числовые диапазоны, противоречивые условия, а также предложи рекомендации по их исправлению.\\n\n",
    "        Вывод должен содержать список обнаруженных проблем и рекомендации для корректировки требований.\n",
    "        \"\"\"\n",
    "    ), HumanMessage(content=rag_message)]\n",
    "    time.sleep(1)\n",
    "    resp_req = gigachat_model.invoke(messages)\n",
    "    memory_imp.append(\"Анализ требований\", resp_req.content)\n",
    "    \n",
    "    return resp_req.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11fd9724",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def alignment_checker(code: str, tz: str) -> str:\n",
    "    \"\"\" \n",
    "    Проверяет код пользователя code на соответсвие бизнес требованию tz и возвращает эту проверку.\n",
    "    \n",
    "    code: код пользователя str\n",
    "    tz:  бизнес требование str\n",
    "    return: Анализ соответсвия кода бизнес требованию str\n",
    "    \"\"\"\n",
    "    print(\"Начал анализ соответствия!!!!!\")\n",
    "    if 'Требования пользователя' in memory_imp.data: \n",
    "        tz = memory_imp.read('Требования пользователя')\n",
    "    if 'Код пользователя' in memory_imp.data: \n",
    "        code = memory_imp.read('Код пользователя') \n",
    "    combined_input = f\"Требования:\\n{code}\\n\\nКод:\\n{tz}\"\n",
    "    messages_align = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\" Задача: Сопоставить текстовые требования и исходный код, выявить несоответствия между задокументированным функционалом и реализованными возможностями.\\n\n",
    "                Важно: Если в требованиях описан функционал A, но в коде он отсутствует, это является несоответствием и должно быть указано.\\n\n",
    "                Если в коде присутствует функционал, который не указан в требованиях, это не является ошибкой, так как требования могут быть неполными.\\n\n",
    "                Обрати внимание на отсутствие задокументированных функций, несоответствие числовых диапазонов, а также нарушения архитектурных требований.\\n\n",
    "                Выведи отчет, в котором указаны: требования, которые не реализованы в коде, а также даны рекомендации по исправлению обнаруженных несоответствий.\n",
    "        \"\"\"\n",
    "    ), HumanMessage(content=combined_input)]\n",
    "    time.sleep(1)\n",
    "    resp_alig = gigachat_model.invoke(messages_align)\n",
    "    memory_imp.append(\"Анализ соответствий\", resp_alig.content)\n",
    "    return resp_alig.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca021d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def coder_analyzer(code: str, tz: str) -> str:\n",
    "    \"\"\" \n",
    "    Проверяет код пользователя code, учитывая бизнес требование tz, и возвращает его проверку.\n",
    "    \n",
    "    code: код пользователя str\n",
    "    tz:  бизнес требование str\n",
    "    return: проверка кода str\n",
    "    \"\"\"\n",
    "    print(\"Начал анализ кода!!!!!\")\n",
    "    \n",
    "    if 'Требования пользователя' in memory_imp.data: \n",
    "        tz = memory_imp.read('Требования пользователя')\n",
    "    if 'Код пользователя' in memory_imp.data: \n",
    "        code = memory_imp.read('Код пользователя') \n",
    "    messages_сoder = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\"Ты умный помощник-программист, который должен генерировать надежный код строго по заданным требованиям. При работе необходимо соблюдать следующие принципы и правила:\\n\n",
    "                1. Анализ требований: Перед написанием кода внимательно проанализируй все документированные требования. Убедись, что полностью понял задачу, бизнес-логику и ожидаемый функционал.\\n\n",
    "                2. Полнота функционала: Реализуй весь указанный функционал без упущений. Ничего не пропускай – каждая деталь требований должна быть отражена в решении.\\n\n",
    "                3. Соответствие логике и ограничениям: Строго соблюдай бизнес-логику, математические формулы и все ограничения, указанные в требованиях. Решение должно точно соответствовать описанным правилам работы.\\n\n",
    "                4. В ответе верни только код.\n",
    "        \"\"\"\n",
    "    ), HumanMessage(content=tz)]\n",
    "    time.sleep(1)\n",
    "    resp_coder = gigachat_model.invoke(messages_сoder)\n",
    "    \n",
    "    combined_code = f\"Код пользователя:\\n{code}\\n\\nКод LLM:\\n{resp_coder.content}\"\n",
    "    two_code_analyzer = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\"Твоя задача – проанализировать два кода: один предоставлен LLM в качестве справочного бейзлайна, другой – код пользователя.\\n\n",
    "                Проведи тщательное сравнение с акцентом на математическую корректность реализации: убедись, что диапазоны, знаки в неравенствах и логические условия в коде пользователя полностью совпадают с кодом LLM.\\n \n",
    "                Отличия в архитектуре, стиле или организации кода не являются ошибками и могут быть проигнорированы.\\n \n",
    "                В итоговом ответе необходимо сформировать список расхождений, обнаруженных в коде пользователя по сравнению с кодом LLM.\\n\n",
    "                Код LLM предоставлен исключительно для справки – его комментировать не нужно. Если математическая логика в коде пользователя идентична, выведи сообщение об отсутствии расхождений.\n",
    "        \"\"\"\n",
    "    ), HumanMessage(content=combined_code)]\n",
    "    time.sleep(1)\n",
    "    analyzer_coder = gigachat_model.invoke(two_code_analyzer)\n",
    "    \n",
    "    report_generator = [\n",
    "        SystemMessage(\n",
    "            content=\"\"\"Задача: на основе сравнения кода пользователя и кода LLM напиши все обнаруженные ошибки в коде пользователя и рекомендации по их исправлению на том языке программирования, который использовал пользователь.\\n\n",
    "                Включи дополнительную информацию и подробности для каждого найденного пункта.\\n\n",
    "                Вывод должен быть структурированным и понятным для разработчиков и аналитиков.\n",
    "                Не упоминай про код LLM и про другие версии кода в своем ответе.\"\"\"\n",
    "            ), HumanMessage(content=analyzer_coder.content)]\n",
    "    report_generator_answer = gigachat_model.invoke(report_generator)\n",
    "    memory_imp.append(\"Анализ кода\", report_generator_answer.content)\n",
    "            \n",
    "    return report_generator_answer.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29087af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def report_generator(code_data: str, alig_data: str, req_data: str) -> str:\n",
    "    \"\"\" \n",
    "    Генерирует итоговый отчет о результате проверки по отчетам всех агентов\n",
    "    \n",
    "    code_data: отчет от анализатора кода str\n",
    "    alig_data: отчет от анализатора соответствий str\n",
    "    req_data: отчет от анализатора требований str\n",
    "    return: итоговый отчет о результате проверки str\n",
    "    \"\"\"\n",
    "    print(\"Генерирую отчет!!!!!\")\n",
    "    \n",
    "    if 'Анализ кода' in memory_imp.data: \n",
    "        code_data = memory_imp.read('Анализ кода')\n",
    "    if 'Анализ соответствий' in memory_imp.data: \n",
    "        alig_data = memory_imp.read('Анализ соответствий') \n",
    "    if 'Анализ требований' in memory_imp.data: \n",
    "        req_data = memory_imp.read('Анализ требований') \n",
    "    \n",
    "    combined_analysis = f\"\"\"Результаты анализа требований:\\n{req_data}\\n\n",
    "        Результаты анализа соответсвий:\\n{alig_data}\\n\n",
    "        Результаты проверки кода пользователя:\\n{code_data}\\n\"\"\"\n",
    "    messages_rep = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\"Задача: на основе отчетов, сформированного предыдущими агентами, выделить только самые серьезные ошибки и недочеты.\\n\n",
    "                 Сформируй суммаризованный отчет, который должен содержать три части, строго в следующей структуре:\\n\\n\n",
    "                  Отчет по требованиям:\\n\n",
    "                 *Отчет по требованиям*\\n\\n\n",
    "                  Отчет соответствия требований и кода:\\n\n",
    "                 *Отчет по коду*\\n\\n\n",
    "                 В раздел \\\"Отчет по требованиям\\\" включи самые критичные проблемы из анализа требований,\n",
    "                 в раздел \\\"Отчет по коду\\\" – наиболее существенные несоответствия между требованиями и кодом\n",
    "        \"\"\"\n",
    "    ), HumanMessage(content=combined_analysis)]\n",
    "    time.sleep(1)\n",
    "    fin_answer = gigachat_model.invoke(messages_rep)\n",
    "    memory_imp.append(\"Финальный отчет\", fin_answer.content)\n",
    "    return fin_answer.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53b266d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def send_document_confluence(link: str) -> str:\n",
    "    \"\"\"\n",
    "    Отправляет финальный отчет в Confluence по ссылке link\n",
    "    \n",
    "    link: ссылка на confluence str\n",
    "    return сообшение об отправке\n",
    "    \"\"\"\n",
    "    # URL для создания комментария\n",
    "    url = \"https://accergeev.atlassian.net/wiki/rest/api/content\"\n",
    "    # Заголовки\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    \n",
    "    final_report = memory_imp.read(\"Финальный отчет\")\n",
    "    \n",
    "    match = re.search(r'/pages/(\\d+)', link)\n",
    "    PAGE_ID = match.group(1)\n",
    "    # Тело запроса\n",
    "    data = {\n",
    "        \"type\": \"comment\",\n",
    "        \"container\": {\n",
    "            \"id\": PAGE_ID,\n",
    "            \"type\": \"page\"\n",
    "        },\n",
    "        \"body\": {\n",
    "            \"storage\": {\n",
    "                \"value\": html.escape(f\"{final_report}\"),\n",
    "                \"representation\": \"storage\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    auth = HTTPBasicAuth(login, token_jira) \n",
    "\n",
    "    # Отправка запроса\n",
    "    response = requests.post(url, auth=auth, headers=headers, json=data)\n",
    "\n",
    "    return \"Комментарий оставлен!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45782272",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def create_jira_task(link: str, summary: str, description: str) -> str:\n",
    "    \"\"\"\n",
    "    Создает задачу в Jira по ссылке link c заголовком summary и описанием description и возвращает её ключ.\n",
    "\n",
    "    link: ссылка на Jira str\n",
    "    summary: заголовок задачи str\n",
    "    description: описание задачи str\n",
    "    return: ключ задачи Jira\n",
    "    \"\"\"\n",
    "    \n",
    "    match = re.search(r'/projects/([A-Z0-9]+)', link)\n",
    "    project_key = match.group(1)\n",
    "    server_name = urlparse(link).netloc\n",
    "    jira_options = {'server': f'https://{server_name}'}\n",
    "    jira = JIRA(options=jira_options, basic_auth=(login, token_jira))\n",
    "\n",
    "    new_issue = jira.create_issue(\n",
    "                project=project_key,\n",
    "                summary=summary,\n",
    "                description=description,\n",
    "                issuetype={\"name\": 'Task'})\n",
    "    return f\"Задача создана {new_issue.key}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c211bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [req_analyzer, coder_analyzer, alignment_checker, report_generator, data_loader_init, data_loader, send_document_confluence] #create_jira_task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7822c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_with_tools = gigachat_model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cf2acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_calling_llm(state: MessagesState):\n",
    "    promt_cesar = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\"Ты асистент, который проверяет бизнес-требования и код, а также их соответствие друг другу.\\n \n",
    "Твоя задача рассказать пользователю, что ты умеешь. Обязательно скажи, что для работы в тебя надо загрузить данные, можно по ссылкам на конфлюенс, а можно текстом\\n\n",
    "Если тебе не хватает каких-то данных, запрашивай их у пользователя.\\n\n",
    "\"\"\" \n",
    "    )] + state[\"messages\"]\n",
    "    return {\"messages\": [ll_with_tools.invoke(promt_cesar)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10674a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\"tool_calling_llm\", tools_condition)\n",
    "builder.add_edge(\"tools\", END)\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b81d062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fdedc51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant:  Привет! Я могу помочь тебе проверить бизнес-требования и код на соответствие друг другу. Вот основные функции, которые я выполняю:\n",
      "- **Анализирую** текстовые бизнес-требования;\n",
      "- Проверяю **соответствие кода требованиям**;\n",
      "- Могу скачать данные из Confluence или принять их от тебя напрямую через текст.\n",
      "\n",
      "Чтобы начать работу, мне нужно получить либо ссылки на документы с требованиями и кодом, либо сам текст этих документов. Если есть какие-либо вопросы или нужна помощь — обращайся!\n",
      "\n",
      "Какую задачу будем решать?\n"
     ]
    }
   ],
   "source": [
    "def chat(thread_id: str):\n",
    "    config_ = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    while(True):\n",
    "        rq = input(\"\")\n",
    "        if rq == \"\":\n",
    "            break\n",
    "        resp = graph.invoke({\"messages\": rq}, config=config_)\n",
    "        print(\"Assistant: \", resp[\"messages\"][-1].content)\n",
    "        time.sleep(1) # For notebook capability\n",
    "\n",
    "chat(\"22\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbdbdb1",
   "metadata": {},
   "source": [
    "### TG Реализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8c856",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-5' coro=<main() running at /var/folders/6j/f0vg68hn36q74_37dv0v8vg40000gn/T/ipykernel_57862/1680615418.py:84>>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:aiogram.dispatcher:Start polling\n",
      "INFO:aiogram.dispatcher:Run polling for bot @GiGACesBot id=7595969817 - 'GiGA-Цезарь_V2'\n",
      "INFO:aiogram.event:Update id=428534717 is handled. Duration 374 ms by bot id=7595969817\n",
      "INFO:aiogram.event:Update id=428534718 is handled. Duration 269 ms by bot id=7595969817\n",
      "INFO:httpx:HTTP Request: POST https://ngw.devices.sberbank.ru:9443/api/v2/oauth \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://gigachat.devices.sberbank.ru/api/v1/chat/completions \"HTTP/1.1 500 Internal Server Error\"\n",
      "INFO:aiogram.event:Update id=428534719 is not handled. Duration 1151 ms by bot id=7595969817\n",
      "ERROR:aiogram.event:Cause exception while process update id=428534719 by bot id=7595969817\n",
      "ResponseError: (URL('https://gigachat.devices.sberbank.ru/api/v1/chat/completions'), 500, b'{\"status\":500,\"message\":\"Internal Server Error\"}\\n', Headers({'server': 'SynGX', 'date': 'Fri, 04 Apr 2025 08:53:38 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '49', 'connection': 'keep-alive', 'access-control-allow-credentials': 'true', 'access-control-allow-headers': 'Origin, X-Requested-With, Content-Type, Accept, Authorization', 'access-control-allow-methods': 'GET, POST, DELETE, OPTIONS', 'access-control-allow-origin': 'https://beta.saluteai.sberdevices.ru', 'x-request-id': '9ec59a14-bcb5-47d4-8771-4d335c054d4f', 'x-session-id': '9aaa9a72-ee5e-4ce5-8460-4f05b5badf54', 'allow': 'GET, POST', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}))\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/aiogram/dispatcher/dispatcher.py\", line 309, in _process_update\n",
      "    response = await self.feed_update(bot, update, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/aiogram/dispatcher/dispatcher.py\", line 158, in feed_update\n",
      "    response = await self.update.wrap_outer_middleware(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/aiogram/dispatcher/middlewares/error.py\", line 25, in __call__\n",
      "    return await handler(event, data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/aiogram/dispatcher/middlewares/user_context.py\", line 56, in __call__\n",
      "    return await handler(event, data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/aiogram/fsm/middleware.py\", line 42, in __call__\n",
      "    return await handler(event, data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/aiogram/dispatcher/event/telegram.py\", line 121, in trigger\n",
      "    return await wrapped_inner(event, kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/aiogram/dispatcher/event/handler.py\", line 43, in call\n",
      "    return await wrapped()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/aiogram/dispatcher/dispatcher.py\", line 276, in _listen_update\n",
      "    return await self.propagate_event(update_type=update_type, event=event, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/aiogram/dispatcher/router.py\", line 146, in propagate_event\n",
      "    return await observer.wrap_outer_middleware(_wrapped, event=event, data=kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/aiogram/dispatcher/router.py\", line 141, in _wrapped\n",
      "    return await self._propagate_event(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/aiogram/dispatcher/router.py\", line 166, in _propagate_event\n",
      "    response = await observer.trigger(event, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/aiogram/dispatcher/event/telegram.py\", line 121, in trigger\n",
      "    return await wrapped_inner(event, kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/aiogram/dispatcher/event/handler.py\", line 43, in call\n",
      "    return await wrapped()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/6j/f0vg68hn36q74_37dv0v8vg40000gn/T/ipykernel_57862/1680615418.py\", line 74, in process_consultant_message\n",
      "    resp = graph.invoke({\"messages\": user_text}, config=сonfig_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/langgraph/pregel/__init__.py\", line 2367, in invoke\n",
      "    for chunk in self.stream(\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/langgraph/pregel/__init__.py\", line 2024, in stream\n",
      "    for _ in runner.tick(\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/langgraph/pregel/runner.py\", line 230, in tick\n",
      "    run_with_retry(\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/langgraph/pregel/retry.py\", line 40, in run_with_retry\n",
      "    return task.proc.invoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 546, in invoke\n",
      "    input = step.invoke(input, config, **kwargs)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/langgraph/utils/runnable.py\", line 310, in invoke\n",
      "    ret = context.run(self.func, *args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/6j/f0vg68hn36q74_37dv0v8vg40000gn/T/ipykernel_57862/2655013357.py\", line 9, in tool_calling_llm\n",
      "    return {\"messages\": [ll_with_tools.invoke(promt_cesar)]}\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/langchain_core/runnables/base.py\", line 5365, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 285, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 861, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 691, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 926, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/langchain_gigachat/chat_models/gigachat.py\", line 436, in _generate\n",
      "    response = self._client.chat(payload)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/gigachat/client.py\", line 295, in chat\n",
      "    return self._decorator(lambda: post_chat.sync(self._client, chat=chat, access_token=self.token))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/gigachat/client.py\", line 254, in _decorator\n",
      "    return call()\n",
      "           ^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/gigachat/client.py\", line 295, in <lambda>\n",
      "    return self._decorator(lambda: post_chat.sync(self._client, chat=chat, access_token=self.token))\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/gigachat/api/post_chat.py\", line 32, in sync\n",
      "    return build_response(response, ChatCompletion)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/kpaq/.pyenv/versions/leetcode/lib/python3.11/site-packages/gigachat/api/utils.py\", line 85, in build_response\n",
      "    raise ResponseError(response.url, response.status_code, response.content, response.headers)\n",
      "gigachat.exceptions.ResponseError: (URL('https://gigachat.devices.sberbank.ru/api/v1/chat/completions'), 500, b'{\"status\":500,\"message\":\"Internal Server Error\"}\\n', Headers({'server': 'SynGX', 'date': 'Fri, 04 Apr 2025 08:53:38 GMT', 'content-type': 'application/json; charset=utf-8', 'content-length': '49', 'connection': 'keep-alive', 'access-control-allow-credentials': 'true', 'access-control-allow-headers': 'Origin, X-Requested-With, Content-Type, Accept, Authorization', 'access-control-allow-methods': 'GET, POST, DELETE, OPTIONS', 'access-control-allow-origin': 'https://beta.saluteai.sberdevices.ru', 'x-request-id': '9ec59a14-bcb5-47d4-8771-4d335c054d4f', 'x-session-id': '9aaa9a72-ee5e-4ce5-8460-4f05b5badf54', 'allow': 'GET, POST', 'strict-transport-security': 'max-age=31536000; includeSubDomains'}))\n",
      "During task with name 'tool_calling_llm' and id 'fceb71f6-36e6-bc8b-ec3c-35af01b7a4d4'\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import logging\n",
    "from aiogram import Bot, Dispatcher, types\n",
    "from aiogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton, CallbackQuery, FSInputFile\n",
    "from aiogram.filters import Command\n",
    "from aiogram.enums import ParseMode\n",
    "from aiogram.client.default import DefaultBotProperties\n",
    "from aiogram.fsm.context import FSMContext\n",
    "from aiogram.fsm.state import StatesGroup, State\n",
    "from aiogram.types import FSInputFile\n",
    "\n",
    "\n",
    "thread_id = random.randint(1, 1000)\n",
    "сonfig_ = {\"configurable\": {\"thread_id\": f'{thread_id}'}}\n",
    "\n",
    "# Инициализация бота и диспетчера\n",
    "bot = Bot(token=TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))\n",
    "dp = Dispatcher()\n",
    "\n",
    "# Определяем состояния для диалога\n",
    "class InsuranceState(StatesGroup):\n",
    "    waiting_for_user = State()\n",
    "\n",
    "# Функция для создания клавиатуры с кнопками\n",
    "def get_main_keyboard():\n",
    "    return InlineKeyboardMarkup(\n",
    "        inline_keyboard=[\n",
    "            [InlineKeyboardButton(text=\"🧑‍💼 Запуск GiGA-Цезарь\", callback_data=\"сaesar\")],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# Обработчик команды /start (показывает кнопки)\n",
    "@dp.message(Command(\"start\"))\n",
    "async def start_handler(message: Message):\n",
    "    await message.answer(\"👋 Привет! Чтобы запустить GiGA-Цезаря, нажми на кнопку:\", reply_markup=get_main_keyboard())\n",
    "\n",
    "    \n",
    "# Обработчик нажатия кнопки \"Остановить диалог\"\n",
    "@dp.message(Command(\"stop\"))\n",
    "async def stop_dialog(message: Message, state: FSMContext):\n",
    "    global сonfig_\n",
    "    memory_imp.clear()\n",
    "    thread_id = random.randint(1, 1000)\n",
    "    сonfig_ = {\"configurable\": {\"thread_id\": f'{thread_id}'}}\n",
    "    await message.answer(\"Диалог завершен. Чтобы начать снова, используйте кнопку 'Перезапустить систему'.\", reply_markup=None)\n",
    "    await state.clear()  # Очищаем состояние\n",
    "\n",
    "    \n",
    "# Обработчик нажатия кнопки \"Перезапустить бота\"\n",
    "@dp.message(Command(\"restart\"))\n",
    "async def restart_bot(message: Message, state: FSMContext):\n",
    "    global сonfig_\n",
    "    memory_imp.clear()\n",
    "    thread_id = random.randint(1, 1000)\n",
    "    сonfig_ = {\"configurable\": {\"thread_id\": f'{thread_id}'}}\n",
    "    await message.answer(\"Система перезапущена. Выберите действие:\", reply_markup=get_main_keyboard())\n",
    "    await state.clear()  # Сбрасываем состояние\n",
    "    \n",
    "    \n",
    "# Обработчик нажатия кнопки \"Запуск GiGA-Цезарь\"\n",
    "@dp.callback_query(lambda c: c.data == \"сaesar\")\n",
    "async def insurance_consultant(callback: CallbackQuery, state: FSMContext):\n",
    "    await callback.message.answer(\"GiGA-Цезарь запущен!\")\n",
    "    await state.set_state(InsuranceState.waiting_for_user)\n",
    "    await callback.answer()  # Закрываем \"часики\" на кнопке\n",
    "    \n",
    "    \n",
    "\n",
    "# Обработчик ввода от пользователя после выбора \"GiGA-Цезарь\"\n",
    "@dp.message(InsuranceState.waiting_for_user)\n",
    "async def process_consultant_message(message: Message, state: FSMContext):\n",
    "    user_text = message.text\n",
    "    resp = graph.invoke({\"messages\": user_text}, config=сonfig_)\n",
    "    try:\n",
    "        time.sleep(1)\n",
    "        await message.answer(resp[\"messages\"][-1].content)\n",
    "    except:\n",
    "        with open('answer_agent.txt', 'w', encoding=\"utf-8\") as f:\n",
    "            f.write(resp[\"messages\"][-1].content)\n",
    "            time.sleep(1)\n",
    "        await message.answer_document(document=FSInputFile('answer_agent.txt'))\n",
    "\n",
    "async def main():\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    await dp.start_polling(bot, skip_updates=True)\n",
    "    \n",
    "\n",
    "loop = asyncio.get_running_loop()\n",
    "loop.create_task(main())  # Запускаем main() без блокировки цикла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2080bc34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leetcode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
